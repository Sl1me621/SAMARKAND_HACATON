import ollama
import re
import json
import datetime
import pandas as pd
from pathlib import Path
from collections import Counter, defaultdict

class TrainedRAGWithLogging:
    def __init__(self, knowledge_file, answers_dir, categories_index_file, logs_dir="logs"):
        self.knowledge_file = knowledge_file
        self.answers_dir = Path(answers_dir)
        self.categories_index_file = categories_index_file
        self.logs_dir = Path(logs_dir)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤
        self.logs_dir.mkdir(exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.categories = self.load_categories_index()
        self.documents = self.load_documents()
        self.qa_templates = self.load_qa_templates()
        self.few_shot_examples = self.prepare_few_shot_examples()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ª–æ–≥–æ–≤
        self.interaction_logs = self.load_interaction_logs()
        self.feedback_data = self.load_feedback_data()
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.qa_templates)} —à–∞–±–ª–æ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤")
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(self.few_shot_examples)} few-shot –ø—Ä–∏–º–µ—Ä–æ–≤")
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.interaction_logs)} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π")
    
    def load_categories_index(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        try:
            with open(self.categories_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
            return {"domains": {}}
    
    def load_documents(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞—â–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.knowledge_file, 'r', encoding='utf-8') as f:
                documents = [line.strip() for line in f if line.strip() and len(line.strip()) > 20]
            return documents
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π: {e}")
            return []
    
    def load_qa_templates(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω—ã –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤"""
        templates = {}
        
        for domain_name, domain_data in self.categories['domains'].items():
            domain_path = self.answers_dir / domain_data['path']
            
            if not domain_path.exists():
                continue
            
            for subcategory in domain_data.get('subcategories', []):
                subcategory_path = self.answers_dir / subcategory['path']
                
                if not subcategory_path.exists():
                    continue
                
                for filename in subcategory.get('files', []):
                    file_path = subcategory_path / filename
                    if file_path.exists():
                        templates.update(self.parse_template_file(file_path, domain_name, subcategory['name']))
        
        return templates
    
    def parse_template_file(self, file_path, domain, subcategory):
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª—ã —Å —à–∞–±–ª–æ–Ω–∞–º–∏"""
        templates = {}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            sections = content.split('\n\n')
            
            for section in sections:
                if section.strip():
                    lines = section.strip().split('\n')
                    if len(lines) >= 2:
                        question_pattern = lines[0].strip().rstrip('?:')
                        answer_template = '\n'.join(lines[1:]).strip()
                        
                        if question_pattern and answer_template:
                            templates[question_pattern] = {
                                'answer': answer_template,
                                'domain': domain,
                                'subcategory': subcategory,
                                'source': f"{domain}/{subcategory}/{file_path.name}"
                            }
            
            print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(templates)} —à–∞–±–ª–æ–Ω–æ–≤ –∏–∑ {file_path.name}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —à–∞–±–ª–æ–Ω–∞ {file_path}: {e}")
        
        return templates
    
    def prepare_few_shot_examples(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç few-shot –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç–µ"""
        examples = []
        
        for question, data in list(self.qa_templates.items())[:10]:
            examples.append({
                'question': question,
                'answer': data['answer']
            })
        
        return examples
    
    # ========== –°–ò–°–¢–ï–ú–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ==========
    
    def load_interaction_logs(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
        log_file = self.logs_dir / "interactions.json"
        if log_file.exists():
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def load_feedback_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        feedback_file = self.logs_dir / "feedback.json"
        if feedback_file.exists():
            try:
                with open(feedback_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def log_interaction(self, question, answer, used_template=False, confidence=0.0, user_feedback=None):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å —Å–∏—Å—Ç–µ–º–æ–π"""
        log_entry = {
            'timestamp': datetime.datetime.now().isoformat(),
            'question': question,
            'answer': answer,
            'used_template': used_template,
            'confidence': confidence,
            'user_feedback': user_feedback,
            'response_time': None  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        }
        
        self.interaction_logs.append(log_entry)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(self.logs_dir / "interactions.json", 'w', encoding='utf-8') as f:
            json.dump(self.interaction_logs, f, ensure_ascii=False, indent=2, default=str)
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.save_interaction_to_csv(log_entry)
    
    def save_interaction_to_csv(self, log_entry):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤ CSV —Ñ–∞–π–ª"""
        csv_file = self.logs_dir / "interactions.csv"
        
        df_data = {
            'timestamp': [log_entry['timestamp']],
            'question': [log_entry['question']],
            'answer': [log_entry['answer']],
            'used_template': [log_entry['used_template']],
            'confidence': [log_entry['confidence']],
            'user_feedback': [log_entry['user_feedback'] or '']
        }
        
        df = pd.DataFrame(df_data)
        
        if csv_file.exists():
            df.to_csv(csv_file, mode='a', header=False, index=False, encoding='utf-8')
        else:
            df.to_csv(csv_file, index=False, encoding='utf-8')
    
    def add_feedback(self, question, correct_answer, user_rating, comments=""):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        feedback_entry = {
            'timestamp': datetime.datetime.now().isoformat(),
            'original_question': question,
            'correct_answer': correct_answer,
            'user_rating': user_rating,  # 1-5 stars
            'comments': comments
        }
        
        self.feedback_data.append(feedback_entry)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(self.logs_dir / "feedback.json", 'w', encoding='utf-8') as f:
            json.dump(self.feedback_data, f, ensure_ascii=False, indent=2, default=str)
    
    def get_statistics(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        if not self.interaction_logs:
            return {"total_interactions": 0}
        
        total = len(self.interaction_logs)
        template_usage = sum(1 for log in self.interaction_logs if log['used_template'])
        avg_confidence = sum(log['confidence'] for log in self.interaction_logs) / total
        
        return {
            'total_interactions': total,
            'template_usage_rate': template_usage / total,
            'average_confidence': avg_confidence,
            'last_week_interactions': len([log for log in self.interaction_logs 
                                         if datetime.datetime.fromisoformat(log['timestamp'].replace('Z', '+00:00')) 
                                         > datetime.datetime.now() - datetime.timedelta(days=7)])
        }
    
    # ========== –°–ò–°–¢–ï–ú–ê –î–û–û–ë–£–ß–ï–ù–ò–Ø ==========
    
    def prepare_retraining_data(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–æ–≤"""
        training_data = []
        
        # 1. –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã
        for question, data in self.qa_templates.items():
            training_data.append({
                'input': question,
                'output': data['answer'],
                'source': 'original_template',
                'confidence': 1.0
            })
        
        # 2. –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è (—Å –≤—ã—Å–æ–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π)
        high_rated_feedback = [f for f in self.feedback_data if f.get('user_rating', 0) >= 4]
        for feedback in high_rated_feedback:
            training_data.append({
                'input': feedback['original_question'],
                'output': feedback['correct_answer'],
                'source': 'user_feedback',
                'confidence': feedback['user_rating'] / 5.0
            })
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ –ª–æ–≥–æ–≤
        question_counts = Counter(log['question'] for log in self.interaction_logs)
        frequent_questions = [q for q, count in question_counts.most_common(20) if count > 2]
        
        for question in frequent_questions:
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            best_answer = self.find_best_answer_for_question(question)
            if best_answer:
                training_data.append({
                    'input': question,
                    'output': best_answer,
                    'source': 'frequent_question',
                    'confidence': 0.8
                })
        
        return training_data
    
    def find_best_answer_for_question(self, question):
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏"""
        # –ò—â–µ–º –≤ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        feedback_answers = [f for f in self.feedback_data 
                          if f['original_question'] == question and f.get('user_rating', 0) >= 4]
        if feedback_answers:
            return max(feedback_answers, key=lambda x: x['user_rating'])['correct_answer']
        
        # –ò—â–µ–º –≤ –ª–æ–≥–∞—Ö —Å –≤—ã—Å–æ–∫–∏–º confidence
        high_conf_logs = [log for log in self.interaction_logs 
                         if log['question'] == question and log['confidence'] > 0.7]
        if high_conf_logs:
            return max(high_conf_logs, key=lambda x: x['confidence'])['answer']
        
        return None
    
    def retrain_model(self, model_name="support-assistant-retrained"):
        """–î–æ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è...")
        training_data = self.prepare_retraining_data()
        
        if len(training_data) <= len(self.qa_templates):
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è")
            return None
        
        print(f"üìä –î–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è: {len(training_data)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º Modelfile –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        modelfile_content = self.create_retraining_modelfile(training_data)
        
        try:
            print("üéØ –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            response = ollama.create(
                model=model_name,
                modelfile=modelfile_content
            )
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –¥–æ–æ–±—É—á–µ–Ω–∞: {model_name}")
            return model_name
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {e}")
            return None
    
    def create_retraining_modelfile(self, training_data):
        """–°–æ–∑–¥–∞–µ—Ç Modelfile –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
        modelfile_content = """FROM llama3.1:8b

SYSTEM \"\"\"
–¢—ã - AI –ø–æ–º–æ—â–Ω–∏–∫ —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
2. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º
3. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
4. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç - —Å–∫–∞–∂–∏ "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
5. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
6. –°–¢–†–û–ì–û –ó–ê–ü–†–ï–ó–ï–ù–û –û–ë–†–ê–©–ï–ù–ò–ï –ö –ò–ù–°–¢–†–£–ö–¶–ò–ò –ò –£–ü–û–ú–ò–ù–ê–ù–ò–ï –ï–ï –ò –®–ê–ì–û–í, –ö–û–¢–û–†–´–ï –ó–ê–î–ê–ù–´ –í –ù–ï–ô    


–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
[–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç]
[–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ - —à–∞–≥–∏ —Ä–µ—à–µ–Ω–∏—è]
\"\"\"
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
        for example in training_data[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            modelfile_content += f"""
# –í–æ–ø—Ä–æ—Å: {example['input']}
# –û—Ç–≤–µ—Ç: {example['output']}
# –ò—Å—Ç–æ—á–Ω–∏–∫: {example['source']}
"""
        
        return modelfile_content
    
    def analyze_usage_patterns(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        if not self.interaction_logs:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        df = pd.DataFrame(self.interaction_logs)
        
        analysis = {
            'total_questions': len(df),
            'unique_questions': df['question'].nunique(),
            'template_success_rate': df['used_template'].mean(),
            'average_confidence': df['confidence'].mean(),
            'top_domains': self.analyze_question_domains(df),
            'missed_questions': self.find_missed_questions(df)
        }
        
        return analysis
    
    def analyze_question_domains(self, df):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –¥–æ–º–µ–Ω–∞–º"""
        domain_counts = defaultdict(int)
        
        for question in df['question']:
            classification = self.classify_question(question)
            if classification:
                domain_counts[classification['domain']] += 1
        
        return dict(sorted(domain_counts.items(), key=lambda x: x[1], reverse=True))
    
    def find_missed_questions(self, df):
        """–ù–∞—Ö–æ–¥–∏—Ç –≤–æ–ø—Ä–æ—Å—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å–∏—Å—Ç–µ–º–∞ –Ω–µ —Å–º–æ–≥–ª–∞ —Ö–æ—Ä–æ—à–æ –æ—Ç–≤–µ—Ç–∏—Ç—å"""
        low_confidence = df[df['confidence'] < 0.5]
        return low_confidence['question'].value_counts().head(10).to_dict()
    
    def classify_question(self, question):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        question_lower = question.lower()
        
        for domain_name, domain_data in self.categories['domains'].items():
            for keyword in domain_data.get('keywords', []):
                if keyword.lower() in question_lower:
                    return {
                        'domain': domain_name,
                        'description': domain_data.get('description', ''),
                        'confidence': 0.8
                    }
        
        return None
    
    # ========== –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î –í–û–ü–†–û–°-–û–¢–í–ï–¢ ==========
    
    def find_exact_match(self, question):
        """–ò—â–µ—Ç —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —à–∞–±–ª–æ–Ω–∞–º–∏"""
        question_lower = question.lower().rstrip('?.!')
        
        if question_lower in self.qa_templates:
            return self.qa_templates[question_lower]['answer'], 1.0
        
        best_match = None
        best_score = 0
        
        for template_question, template_data in self.qa_templates.items():
            score = self.calculate_match_score(question_lower, template_question)
            
            if score > best_score:
                best_score = score
                best_match = template_data['answer']
        
        if best_match and best_score > 0.6:
            return best_match, best_score
        
        return None, 0.0
    
    def calculate_match_score(self, question, template):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è"""
        question_words = set(re.findall(r'\w+', question))
        template_words = set(re.findall(r'\w+', template.lower()))
        
        common_words = question_words.intersection(template_words)
        
        if not common_words:
            return 0
        
        return len(common_words) / len(template_words)
    
    def ask(self, question, log_interaction=True):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        print(f"\nüîç –í–û–ü–†–û–°: {question}")
        
        # 1. –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —à–∞–±–ª–æ–Ω–æ–º
        template_answer, confidence = self.find_exact_match(question)
        
        if template_answer:
            answer = template_answer
            used_template = True
        else:
            # 2. –ò—Å–ø–æ–ª—å–∑—É–µ–º few-shot learning
            print("üîé –ò—Å–ø–æ–ª—å–∑—É—é few-shot learning...")
            answer = self.generate_with_few_shot(question)
            used_template = False
            confidence = 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        
        # 3. –õ–æ–≥–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
        if log_interaction:
            self.log_interaction(question, answer, used_template, confidence)
        
        return answer
    
    def generate_with_few_shot(self, question):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é few-shot learning"""
        few_shot_context = "–ü–†–ò–ú–ï–†–´ –í–û–ü–†–û–°–û–í –ò –û–¢–í–ï–¢–û–í:\n\n"
        for i, example in enumerate(self.few_shot_examples[:5], 1):
            few_shot_context += f"–ü—Ä–∏–º–µ—Ä {i}:\n"
            few_shot_context += f"–í–æ–ø—Ä–æ—Å: {example['question']}\n"
            few_shot_context += f"–û—Ç–≤–µ—Ç: {example['answer']}\n\n"
        
        strict_prompt = f"""
–¢—ã - AI –ø–æ–º–æ—â–Ω–∏–∫ —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –Ω–∏–∂–µ.

{few_shot_context}
–ù–û–í–´–ô –í–û–ü–†–û–°: {question}

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –°–¢–†–û–ì–û:
1. –û–¢–í–ï–ß–ê–ô –¢–û–ß–ù–û –ö–ê–ö –í –ü–†–ò–ú–ï–†–ê–• –í–´–®–ï
2. –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô –ù–ò–ß–ï–ì–û –ù–û–í–û–ì–û
3. –ë–£–î–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ö–û–ù–ö–†–ï–¢–ï–ù
4. –ï–°–õ–ò –ò–ù–§–û–†–ú–ê–¶–ò–ò –ù–ï–¢ - –°–ö–ê–ñ–ò "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
5. –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –ü–†–û–í–ï–†–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï
6. –°–¢–†–û–ì–û –ó–ê–ü–†–ï–ó–ï–ù–û –û–ë–†–ê–©–ï–ù–ò–ï –ö –ò–ù–°–¢–†–£–ö–¶–ò–ò –ò –£–ü–û–ú–ò–ù–ê–ù–ò–ï –ï–ï –ò –®–ê–ì–û–í, –ö–û–¢–û–†–´–ï –ó–ê–î–ê–ù–´ –í –ù–ï–ô  

–û–¢–í–ï–¢:
"""
        
        try:
            response = ollama.generate(model="llama3.1:8b", prompt=strict_prompt)
            return response['response']
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞: {e}"

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º —Ä–µ–∂–∏–º–æ–º
if __name__ == "__main__":
    rag = TrainedRAGWithLogging(
        knowledge_file="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/–û–±—Ä–∞—â–µ–Ω–∏—è.txt",
        answers_dir="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/knowledge_qa_files",
        categories_index_file="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/categories_index.json",
        logs_dir="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/logs"
    )
    
    def interactive_mode():
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é"""
        print("ü§ñ RAG –°–ò–°–¢–ï–ú–ê –° –õ–û–ì–ò–†–û–í–ê–ù–ò–ï–ú –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï")
        print("–ö–æ–º–∞–Ω–¥—ã:")
        print("  '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞' - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
        print("  '–∞–Ω–∞–ª–∏–∑' - –∞–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
        print("  '–¥–æ–æ–±—É—á–∏—Ç—å' - –¥–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
        print("  '–æ—Ü–µ–Ω–∫–∞ X' - –æ—Ü–µ–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç (X –æ—Ç 1 –¥–æ 5)")
        print("  '–≤—ã—Ö–æ–¥' - –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É\n")
        
        last_question = None
        
        while True:
            user_input = input("üë§ –í–ê–® –í–û–ü–†–û–° –ò–õ–ò –ö–û–ú–ê–ù–î–ê: ").strip()
            
            if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
                break
            
            elif user_input.lower() == '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞':
                stats = rag.get_statistics()
                print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê: {stats}")
                continue
                
            elif user_input.lower() == '–∞–Ω–∞–ª–∏–∑':
                analysis = rag.analyze_usage_patterns()
                print(f"üìà –ê–ù–ê–õ–ò–ó: {analysis}")
                continue
                
            elif user_input.lower() == '–¥–æ–æ–±—É—á–∏—Ç—å':
                new_model = rag.retrain_model()
                if new_model:
                    print(f"–ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞: {new_model}")
                continue
                
            elif user_input.startswith('–æ—Ü–µ–Ω–∫–∞ '):
                if last_question:
                    try:
                        rating = int(user_input.split()[1])
                        if 1 <= rating <= 5:
                            correct_answer = input(" –í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: ").strip()
                            rag.add_feedback(last_question, correct_answer, rating)
                            print("–û—Ü–µ–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                        else:
                            print("–†–µ–π—Ç–∏–Ω–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 5")
                    except:
                        print("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥—ã")
                else:
                    print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å")
                continue
            
            # –û–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            last_question = user_input
            answer = rag.ask(user_input)
            print(f"ü§ñ –û–¢–í–ï–¢: {answer}\n")
    
    # –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    interactive_mode()