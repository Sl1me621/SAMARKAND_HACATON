import ollama
import re
import os
from pathlib import Path
from collections import Counter

class EnhancedRAG:
    def __init__(self, knowledge_file, answers_dir):
        self.knowledge_file = knowledge_file
        self.answers_dir = Path(answers_dir)
        self.documents = self.load_documents()
        self.qa_database = self.load_qa_database()
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.documents)} –æ–±—Ä–∞—â–µ–Ω–∏–π –∏ {len(self.qa_database)} QA –ø–∞—Ä")
    
    def load_documents(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞—â–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.knowledge_file, 'r', encoding='utf-8') as f:
                documents = [line.strip() for line in f if line.strip() and len(line.strip()) > 20]
            return documents
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π: {e}")
            return []
    
    def load_qa_database(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫"""
        qa_database = {}
        
        if not self.answers_dir.exists():
            print(f"–ü–∞–ø–∫–∞ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.answers_dir}")
            return qa_database
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–∞–ø–∫–∞–º –∏ –ø–æ–¥–ø–∞–ø–∫–∞–º
        for topic_dir in self.answers_dir.iterdir():
            if topic_dir.is_dir():
                topic_name = topic_dir.name
                
                # –ò—â–µ–º —Ñ–∞–π–ª—ã .md –∏ .txt –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
                for file_path in topic_dir.rglob("*.md"):
                    qa_database.update(self.parse_qa_file(file_path, topic_name))
                
                for file_path in topic_dir.rglob("*.txt"):
                    qa_database.update(self.parse_qa_file(file_path, topic_name))
        
        return qa_database
    
    def parse_qa_file(self, file_path, topic):
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏-–æ—Ç–≤–µ—Ç–∞–º–∏"""
        qa_pairs = {}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
            if file_path.suffix == '.md':
                # –î–ª—è Markdown —Ñ–∞–π–ª–æ–≤ - –∏—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–¥ –Ω–∏–º–∏
                sections = re.split(r'#+\s+', content)
                for section in sections[1:]:  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é –ø—É—Å—Ç—É—é —Å–µ–∫—Ü–∏—é
                    if section.strip():
                        lines = section.strip().split('\n')
                        question = lines[0].strip()
                        answer = '\n'.join(lines[1:]).strip()
                        if question and answer:
                            qa_pairs[question] = {
                                'answer': answer,
                                'topic': topic,
                                'subtopic': file_path.parent.name,
                                'source': file_path.name
                            }
            else:
                # –î–ª—è TXT —Ñ–∞–π–ª–æ–≤ - –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç –≤–æ–ø—Ä–æ—Å: –æ—Ç–≤–µ—Ç
                lines = content.split('\n')
                current_question = None
                current_answer = []
                
                for line in lines:
                    line = line.strip()
                    if line.endswith('?') or line.endswith(':'):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ø–∞—Ä—É
                        if current_question and current_answer:
                            qa_pairs[current_question] = {
                                'answer': '\n'.join(current_answer),
                                'topic': topic,
                                'subtopic': file_path.parent.name,
                                'source': file_path.name
                            }
                        
                        current_question = line.rstrip('?:')
                        current_answer = []
                    elif current_question and line:
                        current_answer.append(line)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞—Ä—É
                if current_question and current_answer:
                    qa_pairs[current_question] = {
                        'answer': '\n'.join(current_answer),
                        'topic': topic,
                        'subtopic': file_path.parent.name,
                        'source': file_path.name
                    }
            
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(qa_pairs)} QA –ø–∞—Ä –∏–∑ {file_path}")
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
        return qa_pairs
    
    def find_relevant_qa(self, query, top_k=3):
        """–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã"""
        query_words = set(re.findall(r'\w+', query.lower()))
        
        scored_qa = []
        for question, qa_data in self.qa_database.items():
            question_words = set(re.findall(r'\w+', question.lower()))
            common_words = query_words.intersection(question_words)
            score = len(common_words)
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–µ
            answer_words = set(re.findall(r'\w+', qa_data['answer'].lower()))
            score += len(query_words.intersection(answer_words)) * 0.5
            
            if score > 0:
                scored_qa.append((score, question, qa_data))
        
        scored_qa.sort(reverse=True)
        return [(q, data) for score, q, data in scored_qa[:top_k]]
    
    def find_relevant_documents(self, query, top_k=2):
        """–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è"""
        query_words = set(re.findall(r'\w+', query.lower()))
        
        scored_docs = []
        for doc in self.documents:
            doc_words = set(re.findall(r'\w+', doc.lower()))
            common_words = query_words.intersection(doc_words)
            score = len(common_words)
            if score > 0:
                scored_docs.append((score, doc))
        
        scored_docs.sort(reverse=True)
        return [doc for score, doc in scored_docs[:top_k]]
    
    def ask(self, question):
        """–ó–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å —Å–∏—Å—Ç–µ–º–µ RAG"""
        if not self.qa_database and not self.documents:
            return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞"
        
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ QA –ø–∞—Ä—ã
        relevant_qa = self.find_relevant_qa(question)
        relevant_docs = self.find_relevant_documents(question)
        
        if not relevant_qa and not relevant_docs:
            return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_parts = []
        
        if relevant_qa:
            context_parts.append("=== –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô (–≤–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã) ===")
            for i, (q, qa_data) in enumerate(relevant_qa, 1):
                context_parts.append(f"{i}. –í–û–ü–†–û–°: {q}")
                context_parts.append(f"   –û–¢–í–ï–¢: {qa_data['answer']}")
                context_parts.append(f"   –¢–µ–º–∞: {qa_data['topic']} -> {qa_data['subtopic']}")
                context_parts.append("")
        
        if relevant_docs:
            context_parts.append("=== –ü–û–•–û–ñ–ò–ï –û–ë–†–ê–©–ï–ù–ò–Ø ===")
            for i, doc in enumerate(relevant_docs, 1):
                context_parts.append(f"{i}. {doc}")
        
        context = "\n".join(context_parts)
        
        prompt = f"""
        –¢—ã - AI –ø–æ–º–æ—â–Ω–∏–∫ —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –¢—ã –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã, –Ω–∞–π–¥–µ
        
        {context}
        
        –ù–û–í–´–ô –í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {question}
        
        –ò–ù–°–¢–†–£–ö–¶–ò–Ø:
        1. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        2. –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –±–∞–∑–µ - –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ
        3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        4. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ –ø–æ–ª–µ–∑–µ–Ω
        5. –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ —Ä–µ—à–µ–Ω–∏—è
        
        –û–¢–í–ï–¢:
        """
        
        try:
            response = ollama.generate(model="llama3.1:8b", prompt=prompt)
            return response['response']
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"
    
    def get_statistics(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º"""
        topics = Counter()
        subtopics = Counter()
        
        for qa_data in self.qa_database.values():
            topics[qa_data['topic']] += 1
            subtopics[qa_data['subtopic']] += 1
        
        return {
            'total_questions': len(self.qa_database),
            'total_documents': len(self.documents),
            'topics': dict(topics),
            'subtopics': dict(subtopics)
        }

def main():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π
    KNOWLEDGE_FILE = "/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/–û–±—Ä–∞—â–µ–Ω–∏—è.txt"
    ANSWERS_DIR = "/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/knowledge_qa_files"
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É RAG
    print("üîÑ –ó–ê–ì–†–£–ó–ö–ê RAG –°–ò–°–¢–ï–ú–´...")
    rag = EnhancedRAG(KNOWLEDGE_FILE, ANSWERS_DIR)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = rag.get_statistics()
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –í–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤: {stats['total_questions']}")
    print(f"   –û–±—Ä–∞—â–µ–Ω–∏–π: {stats['total_documents']}")
    print(f"   –¢–µ–º: {len(stats['topics'])}")
    print(f"   –ü–æ–¥—Ç–µ–º: {len(stats['subtopics'])}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ —Ñ–∞–π–ª–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π
    print(f"\nüîç –í–´–ë–ò–†–ê–ï–ú –¢–ï–°–¢–û–í–´–ï –í–û–ü–†–û–°–´ –ò–ó –§–ê–ô–õ–ê...")
    test_questions = rag.documents[:10]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ–±—Ä–∞—â–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞
    
    print("=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï RAG –°–ò–°–¢–ï–ú–´ ===\n")
    
    for i, question in enumerate(test_questions, 1):
        print(f"üß™ –¢–ï–°–¢ {i}/{len(test_questions)}")
        print(f"‚ùì –í–û–ü–†–û–°: {question}")
        
        answer = rag.ask(question)
        print(f"üí° –û–¢–í–ï–¢: {answer}")
        print("-" * 100)

def interactive_mode():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"""
    KNOWLEDGE_FILE = "/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/–û–±—Ä–∞—â–µ–Ω–∏—è.txt"
    ANSWERS_DIR = "/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/knowledge_qa_files"
    rag = EnhancedRAG(KNOWLEDGE_FILE, ANSWERS_DIR)
    
    print("ü§ñ RAG –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï")
    print("–ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã (–¥–ª—è –≤—ã—Ö–æ–¥–∞ –≤–≤–µ–¥–∏—Ç–µ '–≤—ã—Ö–æ–¥')\n")
    
    while True:
        question = input("üë§ –í–ê–® –í–û–ü–†–û–°: ").strip()
        
        if question.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
            print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        
        if not question:
            continue
            
        print("üîç –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π...")
        answer = rag.ask(question)
        print(f"ü§ñ –û–¢–í–ï–¢: {answer}\n")

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
    main()
    
    # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    # interactive_mode()