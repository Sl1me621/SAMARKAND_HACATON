import ollama
import re
import json
from pathlib import Path

class ModelTrainer:
    def __init__(self, answers_dir, categories_index_file):
        self.answers_dir = Path(answers_dir)
        self.categories_index = self.load_categories_index(categories_index_file)
    
    def load_categories_index(self, categories_index_file):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        try:
            with open(categories_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
            return {"domains": {}}
    
    def prepare_training_data(self):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        training_data = []
        
        for domain_name, domain_data in self.categories_index['domains'].items():
            domain_path = self.answers_dir / domain_data['path']
            
            if not domain_path.exists():
                continue
            
            for subcategory in domain_data.get('subcategories', []):
                subcategory_path = self.answers_dir / subcategory['path']
                
                if not subcategory_path.exists():
                    continue
                
                for filename in subcategory.get('files', []):
                    file_path = subcategory_path / filename
                    if file_path.exists():
                        training_data.extend(self.parse_training_examples(file_path))
        
        return training_data
    
    def parse_training_examples(self, file_path):
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        examples = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã-–æ—Ç–≤–µ—Ç—ã
            sections = content.split('\n\n')
            
            for section in sections:
                if section.strip():
                    lines = section.strip().split('\n')
                    if len(lines) >= 2:
                        question = lines[0].strip().rstrip('?:')
                        answer = '\n'.join(lines[1:]).strip()
                        
                        if question and answer:
                            # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                            training_example = {
                                "input": question,
                                "output": answer
                            }
                            examples.append(training_example)
            
            print(f"üìö –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ {file_path.name}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path}: {e}")
        
        return examples
    
    def create_modelfile(self, training_data, model_name="support-assistant"):
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π Modelfile"""
        modelfile_content = f"""FROM llama3.2:1b

SYSTEM \"\"\"
–¢—ã - AI –ø–æ–º–æ—â–Ω–∏–∫ —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
2. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º
3. –ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
4. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç - —Å–∫–∞–∂–∏ "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
5. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
[–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç]
[–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ - —à–∞–≥–∏ —Ä–µ—à–µ–Ω–∏—è]
\"\"\"
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        for example in training_data[:50]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            modelfile_content += f"""
# –í–æ–ø—Ä–æ—Å: {example['input']}
# –û—Ç–≤–µ—Ç: {example['output']}
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Modelfile
        with open("Modelfile", "w", encoding="utf-8") as f:
            f.write(modelfile_content)
        
        print("‚úÖ Modelfile —Å–æ–∑–¥–∞–Ω")
        return "Modelfile"
    
    def train_model(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è"""
        print("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        training_data = self.prepare_training_data()
        
        if not training_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return
        
        print(f"üìä –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(training_data)}")
        
        # –°–æ–∑–¥–∞–µ–º Modelfile
        modelfile_path = self.create_modelfile(training_data)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ü–†–ê–í–ò–õ–¨–ù–´–ú —Å–ø–æ—Å–æ–±–æ–º
        print("üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        try:
            # –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ Modelfile
            response = ollama.create(
                model="support-assistant",
                modelfile=open(modelfile_path, 'r', encoding='utf-8').read()
            )
            print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
            print(f"üìù –ò–º—è –º–æ–¥–µ–ª–∏: support-assistant")
            return "support-assistant"
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            print("üîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±...")
            return self.train_model_alternative(training_data)
    
    def train_model_alternative(self, training_data):
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—É—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ few-shot prompting"""
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥...")
        
        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é RAG —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
        trained_prompts = {}
        
        for example in training_data:
            trained_prompts[example['input']] = example['output']
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        with open("trained_prompts.json", "w", encoding="utf-8") as f:
            json.dump(trained_prompts, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ –û–±—É—á–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ trained_prompts.json")
        return "trained_prompts"

# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
if __name__ == "__main__":
    trainer = ModelTrainer(
        answers_dir="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/knowledge_qa_files",
        categories_index_file="/home/sl1m/hacatons/mosprom/SAMARKAND_HACATON/rosatom_ml/scripts/categories_index.json"
    )
    
    trained_model = trainer.train_model()